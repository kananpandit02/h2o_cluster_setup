# ğŸš€ Distributed Machine Learning Using H2O.ai Cluster Setup

> A hands-on project demonstrating how to build a distributed machine learning cluster using H2O.ai across multiple nodes.

---

## ğŸ§­ Overview

This project focuses on deploying a **multinode H2O.ai cluster** for distributed machine learning. The cluster is used to train and evaluate models on real-world datasets efficiently. We showcase the entire setup from scratch: environment creation, H2O cluster formation, and executing a Random Forest classifier using Python.

---

## ğŸ¯ Objective

- To build and configure a distributed H2O.ai cluster
- To leverage cluster-based computation for machine learning tasks
- To train and evaluate models (Iris dataset) using `H2ORandomForestEstimator`
- To provide a reusable, open, and academic framework for similar projects

---

## ğŸ’¡ Motivation

With the increasing need for scalable machine learning, traditional single-node setups often fall short. H2O.ai offers a powerful, open-source framework that supports multinode computation out-of-the-box. This project aims to make the setup and usage of an H2O.ai distributed cluster accessible and easy to reproduce for students, researchers, and educators.

---
## ğŸ“ Course Project | Ramakrishna Mission Vivekananda Educational and Research Institute, Belur Math  
ğŸ§  Team: Tom and Jerry  
ğŸ‘¨â€ğŸ’» Members: Kanan Pandit , Sudam Paul  
ğŸ“… Date: April 26, 2025



## ğŸ“ Project Structure
## ğŸ“¦ H2O_Cluster_Project


- [`sample_prog.py`](./sample_prog.py) â€“ ML model script using H2O  
- [`h2o_flatfile.txt`](./h2o_flatfile.txt) â€“ IP list of nodes for H2O cluster  
- [`Steps to Create H2O Cluster.txt`](./Steps%20to%20Create%20H2O%20Cluster.txt) â€“ Step-by-step setup guide  
- [`DML_H2O.pdf`](./DML_H2O.pdf) â€“ Final academic project report  
- [`README.md`](./README.md) â€“ Project documentation  
 ## âš™ï¸ Step-by-Step: How to Create a Multinode H2O.ai Cluster

This section walks you through setting up a multinode H2O cluster using virtual environments, Java, and H2O's flatfile configuration method.

---

### âœ… Requirements

- **Java**: Version 8 to 17  
- **Python**: Version 3.12  
- **H2O**: Latest release  
- **Other Tools**: Virtual environment, wget, unzip  
- **Python Libraries**: `h2o`, `numpy`, `pandas` (optional)

---

### ğŸ› ï¸ 1. Create and Activate a Virtual Environment

```bash
python3 -m venv env
source env/bin/activate
```
### ğŸ”„ 2. System Update and Java Installation
```bash
sudo apt update
sudo apt install openjdk-11-jdk
```
H2O requires Java 8 or later. Use java -version and javac -version to verify.
### ğŸ“¦ 3. Install H2O Python Package
```bash
pip install h2o
```
### ğŸ’¾ 4. Download and Extract the H2O Multinode Binary
```bash
wget https://h2o-release.s3.amazonaws.com/h2o/3.46.0.7 -O h2o-latest.zip
unzip h2o-latest.zip
```
Alternatively, search for H2O 3.46.0.7 manually in a browser and download from the official site.
### ğŸ—ƒï¸ 5. Move h2o.jar to Virtual Environment Directory
```bash
cp h2o-3.46.0.7/h2o.jar .
```
### ğŸ§¾ 6. Create a Flatfile with Cluster Node IPs
Create a file called h2o_flatfile.txt in your environment directory with the following format:
```bash
172.20.252.58
172.20.252.53
```
Each line must contain a node's IP address in the cluster.
### ğŸš€ 7. Start the H2O Cluster on Each Node
# On Node 1 (Master):
```bash
java -Xmx2g -jar h2o.jar -name trial1 -port 54323 \-flatfile h2o_flatfile.txt -network 172.20.252.0/24
```
# On Node 2 (Worker):
```bash
java -Xmx2g -jar h2o.jar -name trial1 -port 54323 \-flatfile h2o_flatfile.txt -network 172.20.252.0/24 \-peer 172.20.252.53:54323
(Replace 172.20.252.53 with your actual master node IP.)
```
(Replace 172.20.252.53 with your actual master node IP.)

## ğŸ“Œ Explanation of the -network Option
The -network 172.20.252.0/24 argument:

Uses CIDR notation for subnetting.

Tells H2O to discover and communicate with nodes in the range 172.20.252.1 to 172.20.252.254.

Helps automatic node discovery within the same LAN/subnet.

Subnet Info	Value
Subnet Mask	255.255.255.0
Range	172.20.252.1â€“254
Broadcast	172.20.252.255
### ğŸ§ª 8. Run the ML Program
Open a new terminal in the same environment and run your Python program:
```bash
python sample_prog.py
```
### ğŸ›‘ 9. Shutdown the H2O Cluster
The cluster will automatically shut down if coded like this:
```bash
h2o.cluster().shutdown()
```
Or manually: use CTRL + C on each Java terminal session.
### âœ… Final Notes
All nodes must be in the same network/subnet

Use the same h2o_flatfile.txt and h2o.jar on all nodes

Ensure ports (e.g. 54323) are open across firewalls

Nodes should be able to ping each other

## ğŸ“Š Results

The Distributed Random Forest (DRF) model was evaluated on the Iris dataset using H2O.ai in a distributed cluster setup. The model was trained on 80% of the dataset and tested on the remaining 20% (27 samples).

---

### ğŸ” Model Performance Metrics

| Metric                       | Value                                  |
|------------------------------|----------------------------------------|
| **Accuracy**                 | 92.59%                                 |
| **MSE (Mean Squared Error)** | 0.0378                                 |
| **RMSE (Root Mean Squared Error)** | 0.1945                         |
| **LogLoss**                  | 0.1049                                 |
| **Mean Per-Class Error**     | 0.1444                                 |
| **Overall Error Rate**       | 7.41% (2 misclassifications out of 27) |
| **AUC / AUCPR**              | Not computed (due to multiclass setup or auc_type=NONE) |

---

### ğŸ“Š Confusion Matrix

| Actual \ Predicted | Setosa | Versicolor | Virginica | Error | Count |
|--------------------|--------|------------|-----------|--------|--------|
| **Setosa**         | 14     | 0          | 0         | 0.00   | 14     |
| **Versicolor**     | 0      | 9          | 1         | 0.10   | 10     |
| **Virginica**      | 0      | 1          | 2         | 0.33   | 3      |
| **Totals**         | 14     | 10         | 3         | â€”      | 27     |

> ğŸ“‰ Misclassifications:
> - 1 **Versicolor** â†’ misclassified as **Virginica**  
> - 1 **Virginica** â†’ misclassified as **Versicolor**

---

### ğŸ¯ Classification Report

| Class         | Precision | Recall | F1-Score |
|---------------|-----------|--------|----------|
| **Setosa**     | 1.00      | 1.00   | 1.00     |
| **Versicolor** | 0.90      | 0.90   | 0.90     |
| **Virginica**  | 0.67      | 0.67   | 0.67     |
| **Macro Avg**  | **0.86**  | **0.86** | **0.86** |

---

### ğŸ§  Interpretation

- **Setosa** is perfectly predicted, as expected due to its well-separated features.
- Minor confusion exists between **Versicolor** and **Virginica**, which is common in this dataset.
- Despite a small test set (only 3 Virginica samples), the model maintains a strong **overall accuracy of 92.59%**.
- The F1-Score for **Virginica** is lower due to the limited sample size and 1 misclassification.

âœ… These results demonstrate high performance using H2Oâ€™s distributed Random Forest, even with class imbalance in the test set.



## ğŸ” Optional: Use AutoML with Your Own Dataset

If you're interested in extending this project further or applying it to your own dataset, you can easily integrate H2Oâ€™s AutoML functionality. This will automatically train and evaluate multiple machine learning models.

### ğŸ§ª Steps to Use AutoML

```python
import time
from h2o.automl import H2OAutoML

# â° Start time
localtime = time.asctime(time.localtime(time.time()))
print("Local current time:", localtime)

# âš™ï¸ Run AutoML
aml = H2OAutoML(
    max_models=15,
    seed=1234,
    exclude_algos=["StackedEnsemble"],  # Optional: exclude ensemble if needed
    balance_classes=True
)

aml.train(
    x=featureColumns,
    y=targetColumn,
    training_frame=train,
    validation_frame=valid
)

# â° End time
localtime = time.asctime(time.localtime(time.time()))
print("Local current time:", localtime)
```







### ğŸ™ Acknowledgements

Special thanks to:

**Champak Kumar Dutta**  
Assistant Professor, Department of Data Science  
RKMVERI, Belur Math, West Bengal  

For his guidance, mentorship, and continuous encouragement.

## ğŸ“œ License

This project is licensed under the **Academic Use Only License**.

- âœ… You are free to use, modify, and distribute this work **for academic, research, and educational purposes only**.
- âŒ Commercial use, redistribution, or integration into proprietary products is **strictly prohibited** without prior written permission.

If you wish to use this project beyond academic contexts, please contact the authors for licensing terms.


## ğŸŒ Connect With Us

**Kanan Pandit (B2430051)**  
ğŸŒ [Portfolio](https://kananpanditportfolio.netlify.app/)  
âœ‰ï¸ kananpandit02@gmail.com  

**Sudam Paul (B2430023)**  
ğŸŒ [Portfolio](https://sudam23.github.io/My_Portfolio/)  
âœ‰ï¸ 2002sudam@gmail.com  

**Institution**  
Ramakrishna Mission Vivekananda Educational and Research Institute  
ğŸ“ Belur Math, Howrah, West Bengal  


